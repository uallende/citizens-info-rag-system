{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/m_enmb/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.config import Configure, Property, DataType, Tokenization\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch import Tensor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BitsAndBytesConfig, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    port=8080,\n",
    "    grpc_port=50051,\n",
    "    additional_config=weaviate.config.AdditionalConfig(timeout=(60, 180)),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": openai_api_key  # Replace with your inference API key\n",
    "    }\n",
    ")\n",
    "path_to_pdf = 'pdf_docs'\n",
    "\n",
    "documents_text = []\n",
    "\n",
    "for doc in os.listdir(path_to_pdf):\n",
    "\n",
    "    doc_path = f'{path_to_pdf}/{doc}'\n",
    "    loader = PyPDFLoader(doc_path)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    documents_text.append(docs)\n",
    "\n",
    "documents_text = [item for sublist in documents_text for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "body_vectors = []\n",
    "for d in documents_text:\n",
    "    body = d.page_content\n",
    "    embeddings = model.encode(body)\n",
    "    body_vectors.append(embeddings)\n",
    "\n",
    "document_objs = list()\n",
    "for d in documents_text:\n",
    "    # Extract data from each document\n",
    "    title = d.metadata['source']\n",
    "    page = str(d.metadata['page'])  # page number to string\n",
    "    body = d.page_content\n",
    "\n",
    "    # Prepare properties for the data object\n",
    "    document_objs.append({\n",
    "        \"page\": page,\n",
    "        \"title\": title,\n",
    "        \"body\": body\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"citizens_info_docs\") \n",
    "client.collections.create(\n",
    "    \"citizens_info_docs\",\n",
    "\n",
    "    properties=[  \n",
    "        Property(name=\"page\", data_type=DataType.TEXT),\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"body\", data_type=DataType.TEXT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for i, data_row in enumerate(document_objs):\n",
    "        batch.add_object(\n",
    "            # print(data_row),\n",
    "            properties=data_row,\n",
    "            vector = body_vectors[i],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"citizens_info_docs\") \n",
    "client.collections.create(\n",
    "    \"citizens_info_docs\",\n",
    "\n",
    "    properties=[  \n",
    "        Property(name=\"page\", data_type=DataType.TEXT),\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"body\", data_type=DataType.TEXT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for i, data_row in enumerate(document_objs):\n",
    "        batch.add_object(\n",
    "            # print(data_row),\n",
    "            properties=data_row,\n",
    "            vector = body_vectors[i].tolist(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = collection.query.fetch_objects(\n",
    "    include_vector=True  # Specify names of the vectors to include\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4096\n",
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/SFR-Embedding-Mistral')\n",
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "question = f\"What do I do if my neighbour is having a party\"\n",
    "\n",
    "question_batch_dict = tokenizer(question, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "question_output = encoder(**question_batch_dict)\n",
    "question_embs = last_token_pool(question_output.last_hidden_state, question_batch_dict['attention_mask'])[0].float().cpu().detach().numpy()\n",
    "# question_embs = question_output.last_hidden_state[0][0].float().cpu().detach().numpy()\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "# Convert the NumPy array to a list with a single element\n",
    "# question_embs_list = [question_embs.tolist()]\n",
    "q_emb_list = question_embs.tolist()\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=question_embs.tolist(),  # Pass the list of vectors\n",
    "    target_vector=\"body\", \n",
    "    return_properties=['body', 'title'],\n",
    "    limit=2,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.metadata.distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_enmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
