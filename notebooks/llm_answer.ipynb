{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/m_enmb/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  4.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "from transformers import BitsAndBytesConfig, AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from torch.nn.functional import Tensor\n",
    "import torch, gc\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "print(hf_token)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    'Salesforce/SFR-Embedding-Mistral',\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "    return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def convert_text_to_tokens(text:str, tokenizer, max_length):\n",
    "\n",
    "    batch_dict = tokenizer(text, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "    output = model(**batch_dict)\n",
    "    embeddings = last_token_pool(output.last_hidden_state, batch_dict['attention_mask'])[0].float().cpu().detach().numpy()\n",
    "    return embeddings\n",
    "openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    port=8080,\n",
    "    grpc_port=50051,\n",
    "    additional_config=weaviate.config.AdditionalConfig(timeout=(60, 180)),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": openai_api_key  \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'pdf_docs/Noise pollution and noise complaints.pdf', 'body': 'If your pet is distressed by ﬁreworks, dogstrust.ie have ﬁrework advice and resources available.\\nNoise from homes\\nDomes\\x00c noise is noise from a domes\\x00c se\\x00ng, like a home. Depending on the cause of the noise, you will\\ncomplain in a diﬀerent way. This is outlined below.\\nIf the noise is coming from a person’s home, the Gardaí can ask them to lower noise but they can’t enter the\\nproperty with the sole inten\\x00on of asking them to lower the noise.\\nIf the noise con\\x00nues, you can complain to the District Court (see above).\\nThere is useful informa\\x00on in the leaﬂet on neighbour disputes (pdf) published by FLAC, the Free Legal Advice\\nCentres.\\nNoise from rented proper\\x00es\\nIf there is noise coming from a rented home, you should approach the tenant ﬁrst and ask them to lower the\\nnoise. If this doesn’t work, you can complain to the landlord. This may be a:\\nPrivate landlord\\nLocal authority\\nHousing associa\\x00on\\nPeople who are ren\\x00ng from private landlords or housing associa\\x00ons have certain obliga\\x00ons. These include\\nnot engaging in an\\x00-social behaviour, which includes persistent noise that aﬀects others around them.\\nYou can complain to the Residen\\x00al Tenancies Board (RTB) if a private landlord or housing associa\\x00on doesn’t\\nenforce these obliga\\x00ons.\\nIf the tenant is ren\\x00ng from a local authority housing, they must avoid causing any nuisance such as noise to\\nother proper\\x00es around you. If they do make excessive and persistent noise, they are breaking the tenancy\\nagreement and the local authority can take steps to make sure they follow the terms of the agreement. You can\\nread the legisla\\x00on on noise from rented proper\\x00es.\\nNoise from alarms\\nAll alarm installers must have licences from the Private Security Authority. To get a licence, they have to follow\\ncertain standards. This includes a limit on the length of \\x00me an external alarm can sound for – the maximum\\nunder the European standard is 15 minutes.\\nThe local authority, the EPA or an individual may take ac\\x00on under the EPA Act to deal with breaches of these\\nstandards.\\nYou can read about car alarms in the Noise from transport sec\\x00on below.\\nNoise from dogs\\nIf your neighbour’s dog is barking, you should go to your neighbour directly to try resolve the issue. If this\\ndoesn’t work, you can complain to the District Court.\\nYou can do this by comple\\x00ng a Sec\\x00on 108 Form, which you can get from your local authority or District\\nCourt. Before you do this, you must let the dog owner know that you are making a complaint.\\nTo deal with noise from a dog, the Court can:'}\n",
      "0.3146440386772156\n",
      "{'title': 'pdf_docs/Noise pollution and noise complaints.pdf', 'body': 'When gran\\x00ng planning permission for a building, the local authority can include condi\\x00ons to prevent or\\nreduce noise. These condi\\x00ons can relate to the construc\\x00on or building phase and/or to the use of the\\nbuilding when it is complete.\\nYou can appeal to An Bord Pleanála against these requirements (or the absence of them).\\nFurther informa\\x00on and contacts\\nContact your local authority for more informa\\x00on on noise complaints.\\nContact your local Garda sta\\x00on.\\nEnvironmental Protec\\x00on Agency\\nPO Box 3000\\nJohnstown Castle Estate\\nWexford\\nIreland\\nTel: (053) 916 0600\\nLocall: 0818 33 55 99\\nFax: (053) 916 0699\\nHomepage: h\\x00p://www.epa.ie\\nEmail: info@epa.ie\\nTransport Infrastructure Ireland\\nParkgate Business Centre\\nParkgate Street\\nDublin 8\\nIreland\\nTel: +353 1 646 3600\\nHomepage: h\\x00p://www.\\x00i.ie\\nEmail: info@\\x00i.ie\\nResiden\\x00al Tenancies Board\\nPO Box 47\\nClonakilty\\nCo. Cork\\nIreland\\nOpening Hours: 9am to 5pm\\nTel: 0818 303 037 or 01 702 8100\\nFax: 0818 303 039\\nHomepage: h\\x00p://www.rtb.ie/\\nPage edited: 2 February 2024\\nManage cookie preferences\\nManage preferences'}\n",
      "0.3323918581008911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12617"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/SFR-Embedding-Mistral')\n",
    "max_length = 4096\n",
    "\n",
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "question = f\"What do I do if my neighbour is having a party\"\n",
    "question_embeddings = convert_text_to_tokens(question, tokenizer, max_length)\n",
    "\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=question_embeddings.tolist(),  # Pass the list of vectors\n",
    "    target_vector='default', \n",
    "    return_properties=['body', 'title'],\n",
    "    limit=2,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.metadata.distance)\n",
    "\n",
    "model.cpu()\n",
    "del model, tokenizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# mistralai/Mistral-7B-Instruct-v0.2\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer\n",
    "\n",
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "config.max_position_embeddings = 8096\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "llm_int8_enable_fp32_cpu_offload=True,\n",
    "bnb_4bit_quant_type='nf4',\n",
    "bnb_4bit_use_double_quant=True,\n",
    "bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "model_name_or_path,\n",
    "config=config,\n",
    "trust_remote_code=True,\n",
    "quantization_config=quantization_config,\n",
    "device_map=\"cuda\",\n",
    "offload_folder=\"./offload\"\n",
    ")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.2', token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/m_enmb/lib/python3.11/site-packages/transformers/generation/utils.py:1460: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do I do if my neighbour is having a party: \n",
      "\n",
      "If your neighbor is having a party that is causing noise disturbance, there are several steps you can take:\n",
      "\n",
      "1. Contact your local authority to report the noise and ask if they have any noise control or nuisance regulations in place. They may be able to investigate the noise complaint and take appropriate action.\n",
      "2. Contact your local Garda station to report the noise disturbance. The Garda may be able to intervene if the noise is excessive or causing a disturbance to the peace.\n",
      "3. Contact the Environmental Protection Agency if the noise is coming from an industrial or commercial source. The EPA has the power to investigate and enforce noise regulations.\n",
      "4. If the party is taking place during unsociable hours, you can contact the Residential Tenancies Board if you are renting your property. They can provide advice on how to deal with noise complaints from neighbors.\n",
      "5. If none of the above options provide a satisfactory resolution, you may consider contacting a solicitor or mediator to help resolve the issue.\n",
      "\n",
      "Keep in mind that making a noise complaint can sometimes lead to a lengthy process, and it's essential to be patient and persistent in pursuing a resolution. If you're unsure about any of the steps involved, consider seeking advice from a relevant professional or organization.</s>\n"
     ]
    }
   ],
   "source": [
    "context = o.properties['body']\n",
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": f\"Based on the following context {context}, can you provide an answer to this {question}. If the information is not clear say I don't know but don't make up any information\"},\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(prompt, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(encodeds, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)  # Use encodeds directly\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "# Extract the answer after the [/INST] token\n",
    "start_token = \"[/INST]\"\n",
    "start_index = decoded[0].find(start_token)\n",
    "\n",
    "print(f'{question}: \\n')\n",
    "if start_index != -1:\n",
    "    start_index += len(start_token)\n",
    "    answer = decoded[0][start_index:].strip()\n",
    "    print(answer)\n",
    "else:\n",
    "    print(\"Token not found in the generated text.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_enmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
