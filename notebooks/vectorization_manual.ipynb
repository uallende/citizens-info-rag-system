{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.config import Property, DataType\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    port=8080,\n",
    "    grpc_port=50051,\n",
    "    additional_config=weaviate.config.AdditionalConfig(timeout=(60, 180)),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": openai_api_key  # Replace with your inference API key\n",
    "    }\n",
    ")\n",
    "path_to_pdf = 'pdf_docs'\n",
    "\n",
    "documents_text = []\n",
    "\n",
    "for doc in os.listdir(path_to_pdf):\n",
    "\n",
    "    doc_path = f'{path_to_pdf}/{doc}'\n",
    "    loader = PyPDFLoader(doc_path)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    documents_text.append(docs)\n",
    "\n",
    "documents_text = [item for sublist in documents_text for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_objs = list()\n",
    "for d in documents_text:\n",
    "    # Extract data from each document\n",
    "    title = d.metadata['source']\n",
    "    page = str(d.metadata['page'])  # page number to string\n",
    "    body = d.page_content\n",
    "\n",
    "    # Prepare properties for the data object\n",
    "    document_objs.append({\n",
    "        \"page\": page,\n",
    "        \"title\": title,\n",
    "        \"body\": body\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from torch.nn.functional import Tensor\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "encoder = AutoModel.from_pretrained(\n",
    "    'Salesforce/SFR-Embedding-Mistral',\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "    return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/SFR-Embedding-Mistral')\n",
    "max_length = 4096\n",
    "body_vectors = []\n",
    "title_vectors = []\n",
    "\n",
    "for d in documents_text:\n",
    "\n",
    "    body = d.page_content\n",
    "    title = d.metadata['source']\n",
    "    body_batch_dict = tokenizer(body, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "    title_batch_dict = tokenizer(title, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "    with torch.no_grad():\n",
    "        body_outputs = encoder(**body_batch_dict)\n",
    "        title_outputs = encoder(**title_batch_dict)\n",
    "    body_embs = last_token_pool(body_outputs.last_hidden_state, body_batch_dict['attention_mask'])[0].float().cpu().detach().numpy()\n",
    "    title_embs = last_token_pool(title_outputs.last_hidden_state, title_batch_dict['attention_mask'])[0].float().cpu().detach().numpy()\n",
    "\n",
    "    body_vectors.append(body_embs)\n",
    "    title_vectors.append(title_embs)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"citizens_info_docs\") \n",
    "client.collections.create(\n",
    "    \"citizens_info_docs\",\n",
    "\n",
    "    properties=[  \n",
    "        Property(name=\"page\", data_type=DataType.TEXT),\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"body\", data_type=DataType.TEXT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "\n",
    "with collection.batch.dynamic() as batch:\n",
    "    for i, data_row in enumerate(document_objs):\n",
    "        batch.add_object(\n",
    "            properties=data_row,\n",
    "            vector = body_vectors[i].tolist(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object = collection.query.fetch_objects(\n",
    "    include_vector=True  # Specify names of the vectors to include\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_tokens(text:str, tokenizer, max_length):\n",
    "\n",
    "    batch_dict = tokenizer(text, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "    output = encoder(**batch_dict)\n",
    "    embeddings = last_token_pool(output.last_hidden_state, batch_dict['attention_mask'])[0].float().cpu().detach().numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "question = f\"What do I do if my neighbour is having a party\"\n",
    "question_embeddings = convert_text_to_tokens(question, tokenizer, max_length)\n",
    "\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=question_embeddings.tolist(),  # Pass the list of vectors\n",
    "    target_vector='default', \n",
    "    return_properties=['body', 'title'],\n",
    "    limit=2,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.metadata.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.get(\"citizens_info_docs\")\n",
    "question = f\"What is the cheapeast way to return back to Ireland\"\n",
    "question_embeddings = convert_text_to_tokens(question, tokenizer, max_length)\n",
    "\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=question_embeddings.tolist(),  # Pass the list of vectors\n",
    "    target_vector='default', \n",
    "    return_properties=['body', 'title'],\n",
    "    limit=2,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.metadata.distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
