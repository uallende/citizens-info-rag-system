 - https://ollama.com/blog/embedding-models: different embedding options

 - Deploy Llama3 with TensorRT-LLMðŸ¤™:
https://console.brev.dev/notebook/llama3-tensorrtllm-deployment?=&linkId=100000257228265

 - Supercharge Your RAG with Contextualized Late Interactions:
https://youtu.be/xTzUn3G9YA0

 - Better RAG: Hybrid Search in Chat with Documents | BM25 and Ensemble: https://youtu.be/r2m9DbEmeqI 

 - Find best embedding model for RAG:  https://www.linkedin.com/posts/pau-labarta-bajo-4432074b_machinelearning-llms-mlops-activity-7189171400186757121-k4SV?utm_source=share&utm_medium=member_desktop

- deployment strategy: https://medium.com/@zhikaichen1999/deploying-a-hugging-face-language-model-on-amazon-sagemaker-8e28020a7ced

- similar architecture: https://aws.amazon.com/blogs/machine-learning/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain/

- Approach: Create statements and q&a pairs are a good option. Metadata can save a summary of the chunk and questions is attempting to answer.

- https://platform.openai.com/docs/guides/prompt-engineering/strategy-split-complex-tasks-into-simpler-subtasks

- https://www.youtube.com/watch?v=g1TzbKDNr7M&ab_channel=Diffbot - Knowledge Graphs

- RAG From Scratch: Part 13 (RAPTOR) https://www.youtube.com/watch?v=z_6EeA2LDSw&ab_channel=LangChain 